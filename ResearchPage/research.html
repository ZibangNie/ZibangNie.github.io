<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Zibang Nie ‚Äî Home</title>
    <link rel="stylesheet" href="research.css" />
    <script defer src="research.js"></script>
</head>

<body>

    <!-- Top Nav -->
    <header class="topbar">
        <div class="brand">
            <a class="brand-home" href="../index.html">‚Üê Landing</a>
            <a class="brand-name" href="#top">Zibang Nie</a>
        </div>
       <nav class="nav">
            <a href="../HomePage/home.html">Home</a>
            <a href="../ResearchPage/research.html">Research</a>
            <a href="../ProjectPage/project.html">Projects</a>
            <a href="../PublicationPage/publication.html">Publications</a>
        </nav>
    </header>

    <!-- Main -->
    <main id="top" class="page fade-in">
        <!-- Left Sidebar -->
        <aside class="sidebar card">
            <div class="avatar">
                <img src="../Info/Photo.jpg" alt="Zibang Nie portrait" />
            </div>

            <h2 class="name">Zibang Nie</h2>
            <p class="role">Undergraduate Student</p>

            <ul class="info">
                <li>
                    <span class="icon">
                        <svg viewBox="0 0 24 24" width="18" height="18" aria-hidden="true">
                            <path fill="currentColor"
                                d="M12 2a7 7 0 0 0-7 7c0 5.25 7 13 7 13s7-7.75 7-13a7 7 0 0 0-7-7zm0 9.5a2.5 2.5 0 1 1 0-5 2.5 2.5 0 0 1 0 5z" />
                        </svg>
                    </span>
                    <span>Guitang Rd, Yuhua District, Changsha, China</span>
                </li>
                <li>
                    <span class="icon">üéì</span>
                    <span>Central South University & University of Dundee</span>
                </li>
                <li>
                    <span class="icon">üíª</span>
                    <span>Computer Science</span>
                </li>
                <li>
                    <span class="icon">üìû</span>
                    <span>+86 173 7581 9888</span>
                </li>
                <li id="contact">
                    <span class="icon">
                        <svg viewBox="0 0 24 24" width="18" height="18" aria-hidden="true">
                            <path fill="currentColor"
                                d="M20 4H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2zm-.5 4.25L12 13 4.5 8.25 3 9.5l9 6 9-6-1.5-1.25z" />
                        </svg>
                    </span>
                    <a href="mailto:2542881@dundee.ac.uk">2542881@dundee.ac.uk</a>
                </li>
                <li>
                    <span class="icon">
                        <img src="../Logo/GithubLogo.png" alt="" width="18" height="18" />
                    </span>
                    <a href="https://github.com/ZibangNie" target="_blank" rel="noopener">GitHub</a>
                </li>
            </ul>

            <a class="btn" href="../Info/Zibang_Nie_CV.pdf" download>Download CV</a>
        </aside>

        <!-- Right Content -->
        <section class="content">



            <section id="research1" class="card section">
                <h2 class="subtitle">Efficient Pipeline-Parallel Training &amp; ViT Adversarial Robustness</h2>

                <p>
                    <strong>Role &amp; Dates:</strong> Research Assistant (Jun‚ÄìSep 2023).
                    <strong>Focus:</strong> efficient pipeline-parallel training for large Transformers
                    (<strong>vPipe</strong>) and
                    robustness of Vision Transformers under adversarial attacks.
                </p>

                <p>
                    <strong>Overview.</strong> Implemented and tuned <strong>vPipe</strong> (swap‚Äìrecompute‚Äìpartition)
                    on multi-GPU to
                    reduce pipeline bubbles and activation memory, built PyTorch <strong>DDP</strong> baselines, and
                    evaluated
                    <strong>ViT-Base</strong> vs. <strong>ResNet-18</strong> under <strong>FGSM/I-FGSM</strong> on
                    <strong>CIFAR-10</strong>.
                </p>

                <ul>
                    <li>
                        <strong>Throughput &amp; scaling.</strong> In internal runs, vPipe achieved approximately
                        <strong>2√ó</strong> throughput over PipeDream and enabled training of ~<strong>1.2√ó</strong>
                        larger models.
                    </li>
                    <li>
                        <strong>Robustness.</strong> At <em>Œµ = 0.3</em>, ViT showed ~<strong>50%</strong> less accuracy
                        drop than the CNN baseline;
                        explored cross-model transferability and adversarial retraining protocols.
                    </li>
                    <li>
                        <strong>What I did.</strong> Deployed multi-GPU training (DDP), synchronized logging/metrics,
                        performed partition tuning
                        and layer migration checks for vPipe; implemented FGSM/I-FGSM sweeps, transfer tests, and
                        summarized results.
                    </li>
                </ul>

                <p>
                    <strong>Tech Stack:</strong> PyTorch ¬∑ PyTorch Distributed/<strong>DDP</strong> ¬∑ CUDA/NCCL ¬∑
                    CIFAR-10 ¬∑
                    ViT/ResNet/VGG.
                </p>

                <p>
                    <strong>Related outputs:</strong> methods and datasets connected to
                    <strong>Advanced Engineering Informatics (2024)</strong>,
                    <strong>IEEE/ASME Transactions on Mechatronics (2025)</strong>, and a
                    <strong>2025 SSRN preprint</strong>.
                </p>

                <!-- Image placeholders ‚Äî replace src with your actual image paths -->
                <figure class="project-figure">
                    <img src="../assets/vpipe-overview.png" alt="vPipe pipeline overview (swap‚Äìrecompute‚Äìpartition)">
                    <figcaption>vPipe: swap‚Äìrecompute‚Äìpartition with online repartition and reduced pipeline bubbles.
                    </figcaption>
                </figure>

                <figure class="project-figure">
                    <img src="../assets/robustness-curve.png" alt="Adversarial robustness curves on CIFAR-10">
                    <figcaption>Adversarial robustness: accuracy vs. Œµ for ViT-Base and ResNet-18 under FGSM/I-FGSM.
                    </figcaption>
                </figure>

                <figure class="project-figure">
                    <img src="../assets/multigpu-setup.png" alt="Multi-GPU training setup and utilization">
                    <figcaption>DDP multi-GPU setup and utilization profiling during vPipe experiments.</figcaption>
                </figure>
            </section>

            <section id="research2" class="card section">
                <h2 class="subtitle">RAG Plugin for Wenxin Yiyan ‚Äî Knowledge-Grounded QA</h2>

                <p>
                    <strong>Role &amp; Dates:</strong> Developer (Jan‚ÄìApr 2024).
                    <strong>Focus:</strong> NLP ¬∑ <strong>LLMs</strong> ¬∑ Retrieval-Augmented Generation
                    (<strong>RAG</strong>) ¬∑ LangChain.
                </p>

                <p>
                    <strong>Overview.</strong> Built an end-to-end plugin that fuses <strong>local physics
                        corpora</strong> with
                    <strong>Wenxin Yiyan</strong> via <strong>LangChain</strong> to deliver accurate, source-grounded
                    answers for
                    Physics Tournament (IYPT/CUPT) prep. The system ingests <strong>PDF/DOCX/TXT</strong>, performs
                    <strong>semantic chunking</strong>, computes <strong>HuggingFace embeddings</strong>, and serves
                    results through a
                    <strong>Flask</strong> API consumed by Yiyan.
                </p>

                <ul>
                    <li>
                        <strong>Retrieval &amp; Routing.</strong> Two-level router ‚Üí domain sub-chains; <strong>top-k =
                            3</strong> with
                        score threshold <strong>0.58</strong>; <strong>keyword-augmented</strong> vectors backfill
                        low-score hits;
                        per-turn <strong>memory</strong> stores Q/A and retrieved snippets.
                    </li>
                    <li>
                        <strong>Vector Store.</strong> <strong>Annoy</strong> (cosine) with local persistence; chunking
                        via
                        <strong>RecursiveCharacterTextSplitter</strong> + <strong>NLTKTextSplitter</strong> (hundreds of
                        tokens per chunk).
                    </li>
                    <li>
                        <strong>Prompting.</strong> Templates combine user query + domain blurb + memory + retrieved
                        chunks + answering rules
                        for grounded, verifiable responses.
                    </li>
                    <li>
                        <strong>Integration.</strong> Yiyan ‚Üí HTTP POST ‚Üí <strong>Flask</strong> ‚Üí retrieval &amp;
                        templating ‚Üí JSON answer;
                        logs and simple fallbacks for empty hits.
                    </li>
                    <li>
                        <strong>Testing.</strong> Functional &amp; non-functional tests; parameter sweeps for chunk
                        size/overlap, embedding model,
                        and Annoy <em>n_trees / n_jobs</em>; selected
                        <strong>paraphrase-multilingual-mpnet-base-v2</strong> for production-like runs.
                    </li>
                    <li>
                        <strong>What I did.</strong> Implemented ingestion, indexing &amp; retrieval pipeline; designed
                        router/sub-chain prompts
                        and memory; tuned thresholds; built <strong>Flask</strong> endpoints &amp; deployment scripts;
                        wrote the user manual.
                    </li>
                </ul>

                <p>
                    <strong>Tech Stack:</strong> Python ¬∑ <strong>LangChain</strong> ¬∑ <strong>Flask</strong> ¬∑
                    HuggingFace Embeddings ¬∑
                    <strong>Annoy</strong> ¬∑ jieba/NLTK ¬∑ Wenxin Yiyan API.
                </p>

                <p>
                    <strong>Deliverables:</strong> Design spec ¬∑ User manual ¬∑ Division-of-work &amp; process docs ¬∑
                    Slide deck ¬∑ Working demo.
                </p>

                <!-- Image placeholders ‚Äî replace src with your actual image paths -->
                <figure class="project-figure">
                    <img src="images/Question-handling-process.png"
                        alt="Question handling process flow including text cache and similarity search">
                    <figcaption>Question handling process: from text cache management to similarity search and final
                        answers.</figcaption>
                </figure>

                <figure class="project-figure">
                    <img src="images/keywords-extraction.png"
                        alt="Keyword extraction process with jieba for Chinese and nltk for English keywords">
                    <figcaption>Keyword extraction: jieba for Chinese, nltk for English with stopword filtering.
                    </figcaption>
                </figure>

                <figure class="project-figure">
                    <img src="images/text-buffer.png" alt="Text buffer management in RAG plugin">
                    <figcaption>Text buffer: storing top-k related vectors and response information for Q/A session.
                    </figcaption>
                </figure>

                <figure class="project-figure">
                    <img src="images/keyword-module.png" alt="Keyword vector extraction module and comparison">
                    <figcaption>Keyword module: extraction and vector comparison for efficient search.</figcaption>
                </figure>

                <figure class="project-figure">
                    <img src="images/pretrain-module.png" alt="Pre-trained model integration for query vectorization">
                    <figcaption>Pre-training module: embedding model integration for semantic vectorization.
                    </figcaption>
                </figure>

                <figure class="project-figure">
                    <img src="images/routing-chain-and-specialized-child-chain.png"
                        alt="Routing chain for problem classification and professional sub-chains">
                    <figcaption>Routing chain: categorizing queries into specialized sub-chains for precise responses.
                    </figcaption>
                </figure>
            </section>

            <section id="research3" class="card section">
                <h2 class="subtitle">Deep Learning for Natural Language Processing</h2>

                <p>
                    <strong>Role &amp; Dates:</strong> Student Researcher (Mar‚ÄìJun 2024).
                    <strong>Focus:</strong> Developing an end-to-end pipeline to clean raw text and predict
                    topics/similarity for ad-tech and fintech datasets using deep learning techniques.
                </p>

                <p>
                    <strong>Overview:</strong> The project focused on implementing a pipeline for preprocessing and
                    analyzing large textual datasets in the fields of ad-tech and fintech. This pipeline aimed to
                    predict topics and measure document similarity using various natural language processing (NLP)
                    techniques such as tokenization, stop-word removal, stemming, TF-IDF vectorization, PCA
                    dimensionality reduction, and similarity measures including Jaccard and Cosine similarity. The
                    entire workflow was modularized into utility functions in a Python script, with a dataset of more
                    than 10,000 documents processed and analyzed.
                </p>

                <ul>
                    <li>
                        <strong>Text Preprocessing &amp; Feature Extraction:</strong> Implemented a comprehensive text
                        preprocessing pipeline that included tokenization, stop-word removal, and stemming using the
                        <strong>NLTK</strong> library. After preprocessing, the dataset was vectorized using the
                        <strong>TF-IDF</strong> method, and dimensionality reduction was applied using
                        <strong>PCA</strong> to improve computational efficiency and model performance.
                    </li>
                    <li>
                        <strong>Similarity Metrics:</strong> Used <strong>Jaccard similarity</strong> and <strong>Cosine
                            similarity</strong> metrics to measure the similarity between documents based on their
                        TF-IDF vectors. These metrics helped identify relationships between documents and predict topics
                        effectively.
                    </li>
                    <li>
                        <strong>Outcome:</strong> The pipeline successfully extracted top keywords for each topic and
                        achieved a <strong>0.82 macro-F1 score</strong> on previously unseen data, demonstrating the
                        effectiveness of the preprocessing and vectorization steps in topic prediction. Additionally,
                        the course project was graded <strong>92/100</strong>, and the completion was certified by Prof.
                        Patrick Houlihan.
                    </li>
                </ul>

                <p>
                    <strong>What I Did:</strong> I was responsible for designing and implementing the entire pipeline,
                    starting with text preprocessing and feature extraction, followed by dimensionality reduction and
                    similarity computation. I also tuned parameters such as PCA components and TF-IDF parameters to
                    optimize performance. I wrapped the entire workflow into utility functions within a Python file
                    (utils.py) and handled the processing of over 10,000 documents. Finally, I wrote up the project and
                    contributed to the final presentation.
                </p>

                <p>
                    <strong>Tech Stack:</strong> Python ¬∑ <strong>NLTK</strong> ¬∑ <strong>scikit-learn</strong> ¬∑
                    <strong>Pandas</strong> ¬∑ <strong>PCA</strong> ¬∑ <strong>TF-IDF</strong> ¬∑ <strong>Jaccard</strong>
                    ¬∑ <strong>Cosine Similarity</strong>.
                </p>

                <p>
                    <strong>Related Outputs:</strong> The methods and datasets developed during this project were used
                    to write the project report, as well as form the basis for the academic paper I submitted to the
                    course, which was graded <strong>92/100</strong> by Prof. Patrick Houlihan.
                </p>
            </section>

            <section id="research4" class="card section">
                <h2 class="subtitle">Industrial Froth-Flotation Field Study, Fan-kou Lead-Zinc Mine</h2>

                <p>
                    <strong>Role &amp; Dates:</strong> Student Researcher (Jul‚ÄìAug 2024).
                    <strong>Focus:</strong> Applying computer vision techniques to industrial froth-flotation monitoring
                    to improve grade prediction in mining operations.
                </p>

                <p>
                    <strong>Overview:</strong> The project focused on addressing the challenges of predicting pulp grade
                    in flotation processes using monocular froth images. Due to poor calibration under defocus
                    conditions and the transfer issues with pretrained models, the existing monocular imaging methods
                    were not effective in industrial applications. In this study, we deployed a binocular imaging system
                    at the rougher cells of a lead-zinc mine, synchronized image streams with plant data, and captured
                    high-resolution images to create a novel dataset for further algorithmic studies.
                </p>

                <ul>
                    <li>
                        <strong>Problem:</strong> Monocular froth imaging struggled to predict pulp grade, especially
                        under defocus conditions. Public pretrained models transferred poorly to flotation imagery,
                        limiting their practical application.
                    </li>
                    <li>
                        <strong>Method:</strong>
                        <ul>
                            <li>Deployed a binocular camera rig at rougher flotation cells to capture high-resolution
                                images of the froth.</li>
                            <li>Synchronized image streams with DCS tags, operator logs, and lab assays for accurate
                                data alignment.</li>
                            <li>Curated a dataset of ‚âà8,000 high-res froth images that included various operating
                                conditions and froth behaviors.</li>
                            <li>Supported algorithmic studies by preparing saliency priors and running evaluations of
                                multi-scale cross-attention fusion using a Video-Transformer backend for grade
                                prediction.</li>
                            <li>Assisted with defocus-robust calibration experiments using the ROI-Patched MAM-UNet and
                                progressive training techniques to enhance model stability and accuracy under variable
                                operational conditions.</li>
                            <li>Implemented TS-DDPD (Transfer/Distillation Training and Parallel Deployment) for robust
                                cross-domain model training and conducted industrial validation on real zinc rougher
                                data collected from the field.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Outcome:</strong>
                        <ul>
                            <li>The dataset developed in this study is used in AEI 2024, T-Mech 2025, and a 2025
                                preprint paper.</li>
                            <li>The research contributed to two Chinese patents (CN118887586A; CN118887587A) related to
                                froth-image processing and pulp-grade prediction.</li>
                            <li>Improved vision-based flotation grade prediction by combining binocular imaging and
                                multi-scale attention fusion, which led to better model robustness and more accurate
                                grade monitoring.</li>
                        </ul>
                    </li>
                </ul>

                <p>
                    <strong>Tech Stack:</strong> Python ¬∑ PyTorch ¬∑ OpenCV ¬∑ TensorFlow ¬∑ Multi-GPU training ¬∑
                    ROI-Patched MAM-UNet ¬∑ Video-Transformer ¬∑ TS-DDPD.
                </p>

                <p>
                    <strong>Related Outputs:</strong> The methods and datasets developed in this project are connected
                    to Advanced Engineering Informatics (2024), IEEE/ASME Transactions on Mechatronics (2025), and a
                    2025 SSRN preprint related to froth image analysis and flotation grade monitoring.
                </p>
            </section>


        </section>
    </main>

</body>

</html>